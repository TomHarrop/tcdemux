#!/usr/bin/env python3

from Bio import SeqIO
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord
from pathlib import Path
import pandas as pd
import tempfile
import logging


#############
# FUNCTIONS #
#############

def get_repair_input(wildcards):
    if samples_have_internal_barcodes:
        return {
        'r1': Path(
            workingdir,
            '020_demultiplex',
            '{sample}_r1.fastq'
            ),
        'r2': Path(
            workingdir,
            '020_demultiplex',
            '{sample}_r2.fastq'
            )
        }
    else:
        return{
        'r1': Path(
            workingdir,
            '010_barcode-check',
            '{sample}_r1.fastq'
            ),

        'r2': Path(
            workingdir,
            '010_barcode-check',
            '{sample}_r2.fastq'
            ),
        }


def get_sample_barcode_seq(wildcards):
    sample = wildcards.sample
    my_sample_data = sample_data.loc[sample]
    i5_seq = my_sample_data['i5_index']
    i7_seq = my_sample_data['i7_index']
    i5_rc = Seq(i5_seq).reverse_complement()
    return(f'{i7_seq}+{i5_rc}')


def get_sample_files(wildcards):
    sample = wildcards.sample
    my_sample_data = sample_data.loc[sample]
    r1_file = my_sample_data['r1_file']
    r2_file = my_sample_data['r2_file']
    return {
        'r1': Path(read_directory, r1_file),
        'r2': Path(read_directory, r2_file)
    }


def get_pool_barcode_seq(wildcards):
    pool = wildcards.pool
    pool_data = sample_data[
        sample_data['pool_name'] == pool
        ]
    i5_seq = pool_data['i5_index'][0]
    i7_seq = pool_data['i7_index'][0]
    i5_rc = Seq(i5_seq).reverse_complement()
    return(f'{i7_seq}+{i5_rc}')


def get_pool_files(wildcards):
    pool = wildcards.pool
    pool_data = sample_data[
        sample_data['pool_name'] == pool
        ]
    r1_file = pool_data['r1_file'][0]
    r2_file = pool_data['r2_file'][0]
    return {
        'r1': Path(read_directory, r1_file),
        'r2': Path(read_directory, r2_file)
    }


###########
# GLOBALS #
###########

# config from entrypoint
sample_data_file = Path(config['sample_data_file'])
read_directory = Path(config['read_directory'])

adaptor_files = config['adaptor_files']

outdir = Path(config['outdir'])
logdir = Path(outdir, 'logs')

mem_gb = config['mem_gb']
max_threads = config['threads']

keep_intermediate_files = config['keep_intermediate_files']

########
# MAIN #
########

# set up working direcory
if keep_intermediate_files:
    logging.info(f'Keeping intermediate files in {outdir}')
    workingdir = outdir
else:
    workingdir = tempfile.mkdtemp()
    logging.info(f'Using {workingdir} for intermediate files')

# read the sample data and get a list of samples
sample_data = pd.read_csv(
    sample_data_file,
    index_col='name')

all_samples = sorted(set(sample_data.index))

# Check for the pool_name field.
# If the pool_name field is not present, we don't need to demultiplex internal
# barcodes, we only need to check the external barcodes for errors.
# This is done with with conditionals in the inputs
samples_have_internal_barcodes = False
all_pools = []
if 'pool_name' in sample_data:
    samples_have_internal_barcodes = True
    all_pools = sorted(set(sample_data['pool_name']))
    logging.info(f'Detected pool_name field in {sample_data_file}.')
    logging.info('The following pools will be demuxed using internal barcodes:')
    logging.info(f'{" ".join(all_pools)}')
else:
    logging.info(f'No pool_name field in {sample_data_file}.')
    logging.info('Not attempting to demux by internal barcode.')

# configure resources
logging.info(f'{max_threads} threads provided.')
logging.info(f'{mem_gb} GB RAM provided.')
sample_threads = max(1, max_threads // len(all_samples))
sample_ram = max(8, mem_gb // len(all_samples))
logging.info(f'Using at least {sample_threads} threads per sample.')
logging.info(f'Using at least {sample_ram} GB RAM per sample.')

if samples_have_internal_barcodes:
    pool_threads = max(1, max_threads // len(all_pools))
    pool_ram = max(8, mem_gb // len(all_pools))
    logging.info(f'Using at least {pool_threads} threads per pool.')
    logging.info(f'Using at least {pool_ram} GB RAM per pool.')
else:
    pool_threads = 1
    pool_ram = 8

#########
# RULES #
#########

rule target:
    input:
        expand(
            Path(
                outdir,
                '{sample}_r{r}.fastq.gz'
                ),
            sample=all_samples,
            r=[1, 2]
            ),
        expand(
            Path(
                outdir,
                '{sample}.unpaired.fastq.gz'
                ),
            sample=all_samples
            )

# mask low complexity regions
rule mask:
    input:
        pipe = Path(
            workingdir,
            '040_trim',
            '{sample}.paired.fastq'
            )
    output:
        r1 = Path(
            outdir,
            '{sample}_r1.fastq.gz'
            ),
        r2 = Path(
            outdir,
            '{sample}_r2.fastq.gz'
            )
    log:
        Path(
            logdir,
            'mask',
            '{sample}.log'
            ),
    threads:
        max(1, sample_threads)
    resources:
        time = lambda wildcards, attempt: 10 * attempt,
        mem_gb = max(mem_gb // len(all_samples), 8)
    shell:
        'bbduk.sh '
        '-Xmx{resources.mem_gb}g '
        'threads={threads} '
        'in={input.pipe} '
        'int=t '
        'out={output.r1} '
        'out2={output.r2} '
        'zl=9 '
        'entropy=0.8 '
        'entropywindow=20 '
        'entropymask=t '
        '2> {log} '

rule mask_unpaired:
    input:
        Path(
            workingdir,
            '040_trim',
            '{sample}.unpaired.fastq'
            )
    output:
        Path(
            outdir,
            '{sample}.unpaired.fastq.gz'
            ),
    log:
        Path(
            logdir,
            'mask_unpaired',
            '{sample}.log'
            ),
    threads:
        max(2, sample_threads)    
    resources:
        time = lambda wildcards, attempt: 10 * attempt,
        mem_gb = max(sample_ram, 8)
    shell:
        'bbduk.sh '
        '-Xmx{resources.mem_gb}g '
        'threads={threads} '
        'in={input} '
        'int=f '
        'out={output} '
        'zl=9 '
        'entropy=0.8 '
        'entropywindow=20 '
        'entropymask=t '
        '2> {log} '

# trim adaptors
rule trim:
    input:
        pipe = Path(
            workingdir,
            '030_repair',
            '{sample}.fastq'
            ),
        adaptors = Path(
            outdir, 
            '040_trim',
            'adaptors.fasta'
            ),
    output:
        pipe = pipe(
            Path(
            workingdir,
            '040_trim',
            '{sample}.paired.fastq'
            )
            ),
        unpaired = temp(
            Path(
            workingdir,
            '040_trim',
            '{sample}.unpaired.fastq'
            )
            ),
        stats = Path(
            outdir,
            '040_trim',
            '{sample}.stats'
            )
    params:
        ft = lambda wildcards:
            '' if samples_have_internal_barcodes else 'forcetrimmod=5'
    log:
        Path(
            logdir,
            'trim',
            '{sample}.log'
            )
    threads:
        max(2, sample_threads - 3)    
    resources:
        time = lambda wildcards, attempt: 10 * attempt,
        mem_gb = max(sample_ram, 8)
    shell:
        'bbduk.sh '
        '-Xmx{resources.mem_gb}g '
        'threads={threads} '
        'in={input.pipe} '
        'int=t '
        'out=stdout.fastq '
        'outs={output.unpaired} '
        'ref={input.adaptors} '
        'ktrim=r k=23 mink=11 hdist=1 tpe tbo '
        '{params.ft} '
        'stats={output.stats} '
        '>> {output.pipe} '
        '2> {log} '

rule combine_adaptors:
    input:
        adaptor_files
    output:
        adaptors = Path(
            outdir, 
            '040_trim',
            'adaptors.fasta'
            ),
        duplicates = Path(
            outdir, 
            '040_trim',
            'duplicated_adaptors.fasta'
            )
    log:
        Path(
            logdir,
            'combine_adaptors.log')
    threads:
        2
    resources:
        time = lambda wildcards, attempt: 10 * attempt,
        mem_gb = 4
    shell:
        'cat {input} | '
        'dedupe.sh '
        '-Xmx{resources.mem_gb}g '
        'in=stdin.fasta '
        'out={output.adaptors} '
        'outd={output.duplicates} '
        'absorbcontainment=f '
        'absorbrc=f '
        'ascending=t '
        'exact=t '
        'maxedits=0 '
        'maxsubs=0 '
        'sort=name '
        'touppercase=t '
        'uniquenames=t '
        '2> {log} '

# double check pairing
rule repair:
    input:
        unpack(get_repair_input)
    output:
        pipe(
            Path(
            workingdir,
            '030_repair',
            '{sample}.fastq'
            )
            )
    log:
        Path(
            logdir,
            'repair',
            '{sample}.log')
    threads:
        2
    resources:
        time = lambda wildcards, attempt: 10 * attempt,
        mem_gb = max(mem_gb // len(all_samples), 8)
    shell:
        'repair.sh '
        '-Xmx{resources.mem_gb}g '
        'in={input.r1} '
        'in2={input.r2} '
        'out=stdout.fastq '
        'outs=/dev/null '
        'repair=t '
        'tossbrokenreads=t '
        'tossjunk=t '
        '>> {output} '
        '2> {log}'

# demux using cutadapt
for mypool in all_pools:
    pool_sd = sample_data[sample_data['pool_name'] == mypool]
    pool_samples = sorted(set(pool_sd.index))
    rule:
        input:
            r1 = Path(
                workingdir,
                '010_barcode-check',
                f'{mypool}_r1.fastq'
                ),
            r2 = Path(
                workingdir,
                '010_barcode-check',
                f'{mypool}_r2.fastq'
                ),
            barcodes = Path(
                workingdir,
                '020_demultiplex',
                f'{mypool}.barcodes.fasta'
                )
        output:
            r1 = expand(
                Path(
                    workingdir,
                    '020_demultiplex',
                    '{sample}_r1.fastq'
                    ),
                sample = pool_samples
                ),
            r2 = expand(
                Path(
                    workingdir,
                    '020_demultiplex',
                    '{sample}_r2.fastq'
                    ),
                sample = pool_samples
                )
        params:
            outdir = lambda wildcards, output:
                Path(output[0]).parent.as_posix()
        log:
            Path(
                logdir,
                'cutadapt',
                f'{mypool}.log'
                )
        threads:
            max(2, sample_threads)
        shell:
            'cutadapt '
            '-j {threads} '
            '-e 0 '
            '--no-indels '
            '--pair-adapters '
            '-g ^file:{input.barcodes} '
            '-G ^file:{input.barcodes} '
            '-o {params.outdir}/{{name}}_r1.fastq '
            '-p {params.outdir}/{{name}}_r2.fastq '
            '{input.r1} '
            '{input.r2} '
            '&> {log}'
    rule:
        input:
            sample_data = sample_data_file
        output:
            barcode_file = Path(
                workingdir,
                '020_demultiplex',
                f'{mypool}.barcodes.fasta'
                )
        params:
            pool = mypool
        script:
            'src/write_barcode_file.py'

# check barcodes in pooled fastq files
with tempfile.TemporaryDirectory() as rule_tmpdir:
    rule check_pool_barcodes:
        input:
            unpack(get_pool_files)
        output:
            r1 = Path(
                workingdir,
                '010_barcode-check',
                '{pool}_r1.fastq'
                ),
            r2 = Path(
                workingdir,
                '010_barcode-check',
                '{pool}_r2.fastq'
                ),
            stats = Path(
                outdir,
                '010_barcode-check',
                '{pool}.demux_stats.txt'
                ),
        params:
            barcode_seq = lambda wildcards:
                get_pool_barcode_seq(wildcards),
            out = Path(
                rule_tmpdir,
                '%_r1.fastq'
                ).as_posix(),
            out2 = Path(
                rule_tmpdir,
                '%_r2.fastq'
                ).as_posix()
        log:
            Path(
                logdir,
                'check_pool_barcodes',
                '{pool}.log'
                )
        threads:
            max(5, pool_threads)
        resources:
            mem_gb = max(8, pool_ram)
        shell:
            'streams=$(( {threads}/2 )) ; '
            'mkdir -p {rule_tmpdir} ; '
            'demuxbyname.sh ' 
            'delimiter=: prefixmode=f ' # use the last column
            'names={params.barcode_seq} '
            'out={params.out} '
            'out2={params.out2} '
            'outu=/dev/null '
            'stats={output.stats} '
            'in={input.r1} '
            'in2={input.r2} '
            'streams=$streams '
            '-Xmx{resources.mem_gb}g '
            '2> {log} '
            '&& '
            'mv {rule_tmpdir}/{params.barcode_seq}_r1.fastq '
            '{output.r1} '
            '&& '
            'mv {rule_tmpdir}/{params.barcode_seq}_r2.fastq '
            '{output.r2}'

# check barcodes in individual barcode files
with tempfile.TemporaryDirectory() as tmpdir:
    rule check_sample_barcodes:
        input:
            unpack(get_sample_files)
        output:
            r1 = Path(
                workingdir,
                '010_barcode-check',
                '{sample}_r1.fastq'
                ),
            r2 = Path(
                workingdir,
                '010_barcode-check',
                '{sample}_r2.fastq'
                ),
            stats = Path(
                outdir,
                '010_barcode-check',
                '{sample}.demux_stats.txt'
                ),
        params:
            barcode_seq = lambda wildcards:
                get_sample_barcode_seq(wildcards),
            out = Path(
                tmpdir,
                '%_r1.fastq'
                ).as_posix(),
            out2 = Path(
                tmpdir,
                '%_r2.fastq'
                ).as_posix()
        log:
            Path(
                logdir,
                'check_pool_barcodes',
                '{sample}.log'
                )
        threads:
            max(5, sample_threads)
        resources:
            mem_gb = max(8, sample_ram)
        shell:
            'streams=$(( {threads}/2 )) ; '
            'demuxbyname.sh ' 
            'delimiter=: prefixmode=f ' # use the last column
            'names={params.barcode_seq} '
            'out={params.out} '
            'out2={params.out2} '
            'outu=/dev/null '
            'stats={output.stats} '
            'in={input.r1} '
            'in2={input.r2} '
            'streams=$streams '
            '-Xmx{resources.mem_gb}g '
            '2> {log} '
            '&& '
            'mv {tmpdir}/{params.barcode_seq}_r1.fastq '
            '{output.r1} '
            '&& '
            'mv {tmpdir}/{params.barcode_seq}_r2.fastq '
            '{output.r2}'
